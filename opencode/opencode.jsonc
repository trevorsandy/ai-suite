{
  "$schema": "https://opencode.ai/config.json",
  "model": "ollama/llama3.2",
  "autoupdate": true,
  "provider": {
    "ollama": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "Ollama",
      "options": {
        "baseURL": "http://host.docker.internal:11434/v1"
      },
      "models": {
        "llama3.2": {
          "name": "Llama 3.2"
        },
        "qwen3:8b": {
          "name": "Qwen 3.4 8b"
        }
      }
    },
    "llama.cpp": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "LLaMA.cpp",
      "options": {
        "baseURL": "http://host.docker.internal:8040/v1"
      },
      "models": {
        "gemma-4b": {
          "name": "Gemma3 4b"
        }
      }
    }
  },
  "mcp": {
    "MCP_DOCKER": {
      "type": "remote",
      "url": "http://host.docker.internal:8060/mcp",
      "enabled": true
    }
  }
}